{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dqtuan99/SlimCAE_PyTorch/blob/main/SlimCAE_Pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are many library conflicts in Colab due to preinstalled packages. My first setup cell locks compatible versions and then deliberately kills the kernel (os.kill(os.getpid(), 9)) to force a clean restart. This is expected. After the runtime reconnects, start from Cell 2. Any errors shown when the kernel is terminated can be ignored."
      ],
      "metadata": {
        "id": "QtCN1JFhgdir"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xanp26pRbvQG",
        "outputId": "ceb1aa39-9dc7-412d-f2e0-cf3af4833a94"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">>> pip install --no-cache-dir numpy==1.26.4 scipy==1.11.4\n",
            ">>> pip install --no-cache-dir torch==2.1.2+cu118 torchvision==0.16.2+cu118 torchaudio==2.1.2+cu118 --index-url https://download.pytorch.org/whl/cu118\n",
            ">>> pip install --no-cache-dir pytorch-lightning==1.9.5 hydra-core omegaconf\n",
            ">>> pip install --no-cache-dir pybind11 ninja pybind11-stubgen==0.10.0\n",
            ">>> pip install --no-cache-dir compressai==1.2.6 pytorch-msssim==0.2.1\n"
          ]
        }
      ],
      "source": [
        "# ⬇️ Run this cell first: pin NumPy/torch/core deps → auto-restart\n",
        "import os, sys, subprocess\n",
        "\n",
        "def run(*args):\n",
        "    print(\">>>\", \" \".join(args))\n",
        "    subprocess.check_call(list(args))\n",
        "\n",
        "# (1) Proactively uninstall packages that may pull in NumPy 2.x (ignore if missing)\n",
        "for pkg in [\n",
        "    \"numpy\",\"scipy\",\"opencv-python\",\"opencv-contrib-python\",\"opencv-python-headless\",\n",
        "    \"thinc\",\"tsfresh\",\"sentence-transformers\",\"peft\",\"transformers\"\n",
        "]:\n",
        "    subprocess.call([\"pip\",\"uninstall\",\"-y\",pkg])\n",
        "\n",
        "# (2) Pin the core versions\n",
        "run(\"pip\",\"install\",\"--no-cache-dir\",\"numpy==1.26.4\",\"scipy==1.11.4\")\n",
        "run(\"pip\",\"install\",\"--no-cache-dir\",\n",
        "    \"torch==2.1.2+cu118\",\"torchvision==0.16.2+cu118\",\"torchaudio==2.1.2+cu118\",\n",
        "    \"--index-url\",\"https://download.pytorch.org/whl/cu118\")\n",
        "run(\"pip\",\"install\",\"--no-cache-dir\",\"pytorch-lightning==1.9.5\",\"hydra-core\",\"omegaconf\")\n",
        "run(\"pip\",\"install\",\"--no-cache-dir\",\"pybind11\",\"ninja\",\"pybind11-stubgen==0.10.0\")\n",
        "\n",
        "# (3) CompressAI (incl. GDN deps) and MS-SSIM\n",
        "run(\"pip\",\"install\",\"--no-cache-dir\",\"compressai==1.2.6\",\"pytorch-msssim==0.2.1\")\n",
        "\n",
        "# Show versions\n",
        "import numpy, torch\n",
        "print(\"NumPy:\", numpy.__version__)\n",
        "print(\"Torch:\", torch.__version__)\n",
        "\n",
        "print(\"\\n🔁 Restarting runtime… (after reconnect, continue from Cell 2)\")\n",
        "os.kill(os.getpid(), 9)  # ← force-restart the Colab kernel\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, sys, subprocess, shutil, site, inspect, pathlib\n",
        "\n",
        "REPO = \"/content/cbench_BaSIC\"\n",
        "URL  = \"https://github.com/worldlife123/cbench_BaSIC.git\"\n",
        "\n",
        "def run(cmd, cwd=None, check=False):\n",
        "    print(\">>>\", \" \".join(cmd))\n",
        "    p = subprocess.run(cmd, cwd=cwd, text=True, capture_output=True)\n",
        "    # dump full logs\n",
        "    if p.stdout:\n",
        "        print(p.stdout)\n",
        "    if p.returncode != 0:\n",
        "        print(\"❌ STDERR:\\n\", p.stderr)\n",
        "        if check:\n",
        "            raise subprocess.CalledProcessError(p.returncode, cmd)\n",
        "    return p.returncode == 0\n",
        "\n",
        "# 0) Required packages (Cell 1 should have installed these; reinforce if missing)\n",
        "run([sys.executable,\"-m\",\"pip\",\"install\",\"--no-cache-dir\",\n",
        "     \"compressai==1.2.6\",\"pytorch-msssim==0.2.1\"])\n",
        "run([sys.executable,\"-m\",\"pip\",\"install\",\"--no-cache-dir\",\n",
        "     \"pybind11\",\"ninja\",\"pybind11-stubgen==0.10.0\"])\n",
        "\n",
        "# 1) Clean clone/reset\n",
        "if not os.path.isdir(REPO):\n",
        "    run([\"git\",\"clone\",URL,REPO], check=True)\n",
        "else:\n",
        "    run([\"git\",\"fetch\"], cwd=REPO, check=True)\n",
        "    run([\"git\",\"reset\",\"--hard\",\"origin/main\"], cwd=REPO, check=True)\n",
        "\n",
        "# 2) Remove previous build artifacts + stale egg-link\n",
        "for p in [\"build\",\"cbench.egg-info\"]:\n",
        "    shutil.rmtree(os.path.join(REPO,p), ignore_errors=True)\n",
        "\n",
        "for sp in set(site.getsitepackages() + [site.getusersitepackages()]):\n",
        "    egg = os.path.join(sp, \"cbench.egg-link\")\n",
        "    if os.path.exists(egg):\n",
        "        print(\"🧹 remove:\", egg)\n",
        "        os.remove(egg)\n",
        "\n",
        "# 3) Editable install with build isolation disabled (important!)\n",
        "ok = run([sys.executable,\"-m\",\"pip\",\"install\",\"--no-build-isolation\",\"-e\",REPO])\n",
        "\n",
        "# 4) Fallback to setup.py if pip -e fails\n",
        "if not ok:\n",
        "    print(\"⚠️ pip -e failed → trying fallback: setup.py build develop\")\n",
        "    ok = run([sys.executable,\"setup.py\",\"build\",\"develop\"], cwd=REPO)\n",
        "\n",
        "if not ok:\n",
        "    raise SystemExit(\"❌ Install failed. Check STDERR above.\")\n",
        "\n",
        "# 5) Import test\n",
        "try:\n",
        "    import cbench\n",
        "except ModuleNotFoundError:\n",
        "    # Path fallback (in case only egg-link was created or nested layout)\n",
        "    sys.path.insert(0, REPO)\n",
        "    alt = os.path.join(REPO, \"cbench_BaSIC\")\n",
        "    if os.path.isdir(alt):\n",
        "        sys.path.insert(0, alt)\n",
        "    import cbench\n",
        "\n",
        "print(\"cbench from:\", inspect.getfile(cbench))\n",
        "\n",
        "from cbench.nn.layers.slimmable_layers import (\n",
        "    DynamicConv2d, DynamicGDN,\n",
        "    DynamicResidualBlock, DynamicResidualBlockUpsample,\n",
        ")\n",
        "print(\"✅ Layers OK:\", DynamicConv2d, DynamicGDN)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eKIMrZdSbxXs",
        "outputId": "9f131486-9b27-4fe1-eb3d-57dbf7a5eabf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">>> /usr/bin/python3 -m pip install --no-cache-dir compressai==1.2.6 pytorch-msssim==0.2.1\n",
            "Requirement already satisfied: compressai==1.2.6 in /usr/local/lib/python3.11/dist-packages (1.2.6)\n",
            "Requirement already satisfied: pytorch-msssim==0.2.1 in /usr/local/lib/python3.11/dist-packages (0.2.1)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from compressai==1.2.6) (0.8.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.11/dist-packages (from compressai==1.2.6) (1.26.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from compressai==1.2.6) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from compressai==1.2.6) (1.11.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from compressai==1.2.6) (3.10.0)\n",
            "Requirement already satisfied: torch>=1.7.1 in /usr/local/lib/python3.11/dist-packages (from compressai==1.2.6) (2.1.2+cu118)\n",
            "Requirement already satisfied: torch-geometric>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from compressai==1.2.6) (2.6.1)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from compressai==1.2.6) (4.14.1)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from compressai==1.2.6) (0.16.2+cu118)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from compressai==1.2.6) (4.67.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.1->compressai==1.2.6) (3.18.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.1->compressai==1.2.6) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.1->compressai==1.2.6) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.1->compressai==1.2.6) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.1->compressai==1.2.6) (2025.3.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.1->compressai==1.2.6) (2.1.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch-geometric>=2.3.0->compressai==1.2.6) (3.12.15)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch-geometric>=2.3.0->compressai==1.2.6) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch-geometric>=2.3.0->compressai==1.2.6) (3.2.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch-geometric>=2.3.0->compressai==1.2.6) (2.32.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->compressai==1.2.6) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->compressai==1.2.6) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->compressai==1.2.6) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->compressai==1.2.6) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->compressai==1.2.6) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->compressai==1.2.6) (11.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->compressai==1.2.6) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->compressai==1.2.6) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->compressai==1.2.6) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->compressai==1.2.6) (1.17.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric>=2.3.0->compressai==1.2.6) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric>=2.3.0->compressai==1.2.6) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric>=2.3.0->compressai==1.2.6) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric>=2.3.0->compressai==1.2.6) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric>=2.3.0->compressai==1.2.6) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric>=2.3.0->compressai==1.2.6) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric>=2.3.0->compressai==1.2.6) (1.20.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.7.1->compressai==1.2.6) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric>=2.3.0->compressai==1.2.6) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric>=2.3.0->compressai==1.2.6) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric>=2.3.0->compressai==1.2.6) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric>=2.3.0->compressai==1.2.6) (2025.8.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch>=1.7.1->compressai==1.2.6) (1.3.0)\n",
            "\n",
            ">>> /usr/bin/python3 -m pip install --no-cache-dir pybind11 ninja pybind11-stubgen==0.10.0\n",
            "Requirement already satisfied: pybind11 in /usr/local/lib/python3.11/dist-packages (3.0.0)\n",
            "Requirement already satisfied: ninja in /usr/local/lib/python3.11/dist-packages (1.13.0)\n",
            "Requirement already satisfied: pybind11-stubgen==0.10.0 in /usr/local/lib/python3.11/dist-packages (0.10.0)\n",
            "\n",
            ">>> git clone https://github.com/worldlife123/cbench_BaSIC.git /content/cbench_BaSIC\n",
            ">>> /usr/bin/python3 -m pip install --no-build-isolation -e /content/cbench_BaSIC\n",
            "Obtaining file:///content/cbench_BaSIC\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'error'\n",
            "\n",
            "❌ STDERR:\n",
            "   error: subprocess-exited-with-error\n",
            "  \n",
            "  × python setup.py egg_info did not run successfully.\n",
            "  │ exit code: 1\n",
            "  ╰─> See above for output.\n",
            "  \n",
            "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "error: metadata-generation-failed\n",
            "\n",
            "× Encountered error while generating package metadata.\n",
            "╰─> See above for output.\n",
            "\n",
            "note: This is an issue with the package mentioned above, not pip.\n",
            "hint: See above for details.\n",
            "\n",
            "⚠️ pip -e failed → trying fallback: setup.py build develop\n",
            ">>> /usr/bin/python3 setup.py build develop\n",
            "running build\n",
            "running build_py\n",
            "creating build/lib.linux-x86_64-cpython-311/configs\n",
            "copying configs/__init__.py -> build/lib.linux-x86_64-cpython-311/configs\n",
            "copying configs/class_builder.py -> build/lib.linux-x86_64-cpython-311/configs\n",
            "copying configs/trad_lossy.py -> build/lib.linux-x86_64-cpython-311/configs\n",
            "copying configs/lossy_latent_graph_topogroup_abl_kernel.py -> build/lib.linux-x86_64-cpython-311/configs\n",
            "copying configs/lossy_graph_scalable_exp.py -> build/lib.linux-x86_64-cpython-311/configs\n",
            "copying configs/sync_utils.py -> build/lib.linux-x86_64-cpython-311/configs\n",
            "copying configs/lossy_latent_graph_topogroup_abl.py -> build/lib.linux-x86_64-cpython-311/configs\n",
            "copying configs/import_utils.py -> build/lib.linux-x86_64-cpython-311/configs\n",
            "copying configs/env.py -> build/lib.linux-x86_64-cpython-311/configs\n",
            "copying configs/lossy_latent_graph_topogroup.py -> build/lib.linux-x86_64-cpython-311/configs\n",
            "copying configs/lossy_graph_scalable_exp_hp.py -> build/lib.linux-x86_64-cpython-311/configs\n",
            "copying configs/nn.py -> build/lib.linux-x86_64-cpython-311/configs\n",
            "copying configs/nn_imagenet32.py -> build/lib.linux-x86_64-cpython-311/configs\n",
            "creating build/lib.linux-x86_64-cpython-311/cbench\n",
            "copying cbench/__init__.py -> build/lib.linux-x86_64-cpython-311/cbench\n",
            "creating build/lib.linux-x86_64-cpython-311/tests\n",
            "copying tests/import_test.py -> build/lib.linux-x86_64-cpython-311/tests\n",
            "copying tests/__init__.py -> build/lib.linux-x86_64-cpython-311/tests\n",
            "copying tests/ans_test.py -> build/lib.linux-x86_64-cpython-311/tests\n",
            "copying tests/class_builder_test.py -> build/lib.linux-x86_64-cpython-311/tests\n",
            "copying tests/tans_test.py -> build/lib.linux-x86_64-cpython-311/tests\n",
            "copying tests/sync_utils_test.py -> build/lib.linux-x86_64-cpython-311/tests\n",
            "copying tests/autoregressive_test.py -> build/lib.linux-x86_64-cpython-311/tests\n",
            "creating build/lib.linux-x86_64-cpython-311/configs/trainer\n",
            "copying configs/trainer/__init__.py -> build/lib.linux-x86_64-cpython-311/configs/trainer\n",
            "copying configs/trainer/nn_trainer.py -> build/lib.linux-x86_64-cpython-311/configs/trainer\n",
            "copying configs/trainer/basic_trainer.py -> build/lib.linux-x86_64-cpython-311/configs/trainer\n",
            "creating build/lib.linux-x86_64-cpython-311/cbench/codecs\n",
            "copying cbench/codecs/__init__.py -> build/lib.linux-x86_64-cpython-311/cbench/codecs\n",
            "copying cbench/codecs/zstd_wrapper.py -> build/lib.linux-x86_64-cpython-311/cbench/codecs\n",
            "copying cbench/codecs/general_codec.py -> build/lib.linux-x86_64-cpython-311/cbench/codecs\n",
            "copying cbench/codecs/base.py -> build/lib.linux-x86_64-cpython-311/cbench/codecs\n",
            "copying cbench/codecs/binary_codec.py -> build/lib.linux-x86_64-cpython-311/cbench/codecs\n",
            "copying cbench/codecs/pycodecs.py -> build/lib.linux-x86_64-cpython-311/cbench/codecs\n",
            "creating build/lib.linux-x86_64-cpython-311/cbench/benchmark\n",
            "copying cbench/benchmark/__init__.py -> build/lib.linux-x86_64-cpython-311/cbench/benchmark\n",
            "copying cbench/benchmark/base.py -> build/lib.linux-x86_64-cpython-311/cbench/benchmark\n",
            "copying cbench/benchmark/basic_benchmark.py -> build/lib.linux-x86_64-cpython-311/cbench/benchmark\n",
            "copying cbench/benchmark/trainer.py -> build/lib.linux-x86_64-cpython-311/cbench/benchmark\n",
            "copying cbench/benchmark/utils.py -> build/lib.linux-x86_64-cpython-311/cbench/benchmark\n",
            "creating build/lib.linux-x86_64-cpython-311/cbench/data\n",
            "copying cbench/data/__init__.py -> build/lib.linux-x86_64-cpython-311/cbench/data\n",
            "copying cbench/data/base.py -> build/lib.linux-x86_64-cpython-311/cbench/data\n",
            "copying cbench/data/transforms.py -> build/lib.linux-x86_64-cpython-311/cbench/data\n",
            "creating build/lib.linux-x86_64-cpython-311/cbench/modules\n",
            "copying cbench/modules/__init__.py -> build/lib.linux-x86_64-cpython-311/cbench/modules\n",
            "copying cbench/modules/base.py -> build/lib.linux-x86_64-cpython-311/cbench/modules\n",
            "creating build/lib.linux-x86_64-cpython-311/cbench/nn\n",
            "copying cbench/nn/__init__.py -> build/lib.linux-x86_64-cpython-311/cbench/nn\n",
            "copying cbench/nn/base.py -> build/lib.linux-x86_64-cpython-311/cbench/nn\n",
            "copying cbench/nn/trainer.py -> build/lib.linux-x86_64-cpython-311/cbench/nn\n",
            "copying cbench/nn/lr_schedulers.py -> build/lib.linux-x86_64-cpython-311/cbench/nn\n",
            "creating build/lib.linux-x86_64-cpython-311/cbench/benchmark/metrics\n",
            "copying cbench/benchmark/metrics/__init__.py -> build/lib.linux-x86_64-cpython-311/cbench/benchmark/metrics\n",
            "copying cbench/benchmark/metrics/pytorch_distortion.py -> build/lib.linux-x86_64-cpython-311/cbench/benchmark/metrics\n",
            "copying cbench/benchmark/metrics/bj_delta.py -> build/lib.linux-x86_64-cpython-311/cbench/benchmark/metrics\n",
            "copying cbench/benchmark/metrics/base.py -> build/lib.linux-x86_64-cpython-311/cbench/benchmark/metrics\n",
            "copying cbench/benchmark/metrics/detectron2_metrics.py -> build/lib.linux-x86_64-cpython-311/cbench/benchmark/metrics\n",
            "copying cbench/benchmark/metrics/image_classification_metric.py -> build/lib.linux-x86_64-cpython-311/cbench/benchmark/metrics\n",
            "creating build/lib.linux-x86_64-cpython-311/cbench/data/dataloaders\n",
            "copying cbench/data/dataloaders/__init__.py -> build/lib.linux-x86_64-cpython-311/cbench/data/dataloaders\n",
            "copying cbench/data/dataloaders/basic.py -> build/lib.linux-x86_64-cpython-311/cbench/data/dataloaders\n",
            "creating build/lib.linux-x86_64-cpython-311/cbench/data/datasets\n",
            "copying cbench/data/datasets/__init__.py -> build/lib.linux-x86_64-cpython-311/cbench/data/datasets\n",
            "copying cbench/data/datasets/tables.py -> build/lib.linux-x86_64-cpython-311/cbench/data/datasets\n",
            "copying cbench/data/datasets/basic.py -> build/lib.linux-x86_64-cpython-311/cbench/data/datasets\n",
            "copying cbench/data/datasets/tensors.py -> build/lib.linux-x86_64-cpython-311/cbench/data/datasets\n",
            "copying cbench/data/datasets/image_dataset_wrapper.py -> build/lib.linux-x86_64-cpython-311/cbench/data/datasets\n",
            "copying cbench/data/datasets/binary.py -> build/lib.linux-x86_64-cpython-311/cbench/data/datasets\n",
            "copying cbench/data/datasets/torchvision_datasets.py -> build/lib.linux-x86_64-cpython-311/cbench/data/datasets\n",
            "creating build/lib.linux-x86_64-cpython-311/cbench/modules/transform\n",
            "copying cbench/modules/transform/__init__.py -> build/lib.linux-x86_64-cpython-311/cbench/modules/transform\n",
            "copying cbench/modules/transform/base.py -> build/lib.linux-x86_64-cpython-311/cbench/modules/transform\n",
            "creating build/lib.linux-x86_64-cpython-311/cbench/modules/prior_model\n",
            "copying cbench/modules/prior_model/__init__.py -> build/lib.linux-x86_64-cpython-311/cbench/modules/prior_model\n",
            "copying cbench/modules/prior_model/autoencoder.py -> build/lib.linux-x86_64-cpython-311/cbench/modules/prior_model\n",
            "copying cbench/modules/prior_model/autoencoder_v2.py -> build/lib.linux-x86_64-cpython-311/cbench/modules/prior_model\n",
            "copying cbench/modules/prior_model/base.py -> build/lib.linux-x86_64-cpython-311/cbench/modules/prior_model\n",
            "creating build/lib.linux-x86_64-cpython-311/cbench/modules/context_model\n",
            "copying cbench/modules/context_model/__init__.py -> build/lib.linux-x86_64-cpython-311/cbench/modules/context_model\n",
            "copying cbench/modules/context_model/base.py -> build/lib.linux-x86_64-cpython-311/cbench/modules/context_model\n",
            "creating build/lib.linux-x86_64-cpython-311/cbench/modules/entropy_coder\n",
            "copying cbench/modules/entropy_coder/__init__.py -> build/lib.linux-x86_64-cpython-311/cbench/modules/entropy_coder\n",
            "copying cbench/modules/entropy_coder/tans_utils.py -> build/lib.linux-x86_64-cpython-311/cbench/modules/entropy_coder\n",
            "copying cbench/modules/entropy_coder/torch_base.py -> build/lib.linux-x86_64-cpython-311/cbench/modules/entropy_coder\n",
            "copying cbench/modules/entropy_coder/latent_graph.py -> build/lib.linux-x86_64-cpython-311/cbench/modules/entropy_coder\n",
            "copying cbench/modules/entropy_coder/base.py -> build/lib.linux-x86_64-cpython-311/cbench/modules/entropy_coder\n",
            "copying cbench/modules/entropy_coder/autoregressive.py -> build/lib.linux-x86_64-cpython-311/cbench/modules/entropy_coder\n",
            "copying cbench/modules/entropy_coder/rans.py -> build/lib.linux-x86_64-cpython-311/cbench/modules/entropy_coder\n",
            "copying cbench/modules/entropy_coder/utils.py -> build/lib.linux-x86_64-cpython-311/cbench/modules/entropy_coder\n",
            "copying cbench/modules/entropy_coder/dist_entropy.py -> build/lib.linux-x86_64-cpython-311/cbench/modules/entropy_coder\n",
            "copying cbench/modules/entropy_coder/huffman.py -> build/lib.linux-x86_64-cpython-311/cbench/modules/entropy_coder\n",
            "copying cbench/modules/entropy_coder/ans.py -> build/lib.linux-x86_64-cpython-311/cbench/modules/entropy_coder\n",
            "copying cbench/modules/entropy_coder/bbans.py -> build/lib.linux-x86_64-cpython-311/cbench/modules/entropy_coder\n",
            "copying cbench/modules/entropy_coder/pyrans.py -> build/lib.linux-x86_64-cpython-311/cbench/modules/entropy_coder\n",
            "copying cbench/modules/entropy_coder/fse.py -> build/lib.linux-x86_64-cpython-311/cbench/modules/entropy_coder\n",
            "creating build/lib.linux-x86_64-cpython-311/cbench/modules/preprocessor\n",
            "copying cbench/modules/preprocessor/__init__.py -> build/lib.linux-x86_64-cpython-311/cbench/modules/preprocessor\n",
            "copying cbench/modules/preprocessor/lz77.py -> build/lib.linux-x86_64-cpython-311/cbench/modules/preprocessor\n",
            "copying cbench/modules/preprocessor/autoencoder.py -> build/lib.linux-x86_64-cpython-311/cbench/modules/preprocessor\n",
            "copying cbench/modules/preprocessor/base.py -> build/lib.linux-x86_64-cpython-311/cbench/modules/preprocessor\n",
            "copying cbench/modules/preprocessor/bytes2np.py -> build/lib.linux-x86_64-cpython-311/cbench/modules/preprocessor\n",
            "copying cbench/modules/preprocessor/image_predictor.py -> build/lib.linux-x86_64-cpython-311/cbench/modules/preprocessor\n",
            "copying cbench/modules/preprocessor/lz77_dict_training.py -> build/lib.linux-x86_64-cpython-311/cbench/modules/preprocessor\n",
            "creating build/lib.linux-x86_64-cpython-311/cbench/modules/prior_model/prior_coder\n",
            "copying cbench/modules/prior_model/prior_coder/__init__.py -> build/lib.linux-x86_64-cpython-311/cbench/modules/prior_model/prior_coder\n",
            "copying cbench/modules/prior_model/prior_coder/base.py -> build/lib.linux-x86_64-cpython-311/cbench/modules/prior_model/prior_coder\n",
            "copying cbench/modules/prior_model/prior_coder/pgm_coder.py -> build/lib.linux-x86_64-cpython-311/cbench/modules/prior_model/prior_coder\n",
            "copying cbench/modules/prior_model/prior_coder/compressai_coder.py -> build/lib.linux-x86_64-cpython-311/cbench/modules/prior_model/prior_coder\n",
            "copying cbench/modules/prior_model/prior_coder/mcquic_coder.py -> build/lib.linux-x86_64-cpython-311/cbench/modules/prior_model/prior_coder\n",
            "copying cbench/modules/prior_model/prior_coder/torch_ans.py -> build/lib.linux-x86_64-cpython-311/cbench/modules/prior_model/prior_coder\n",
            "copying cbench/modules/prior_model/prior_coder/sqvae_coder.py -> build/lib.linux-x86_64-cpython-311/cbench/modules/prior_model/prior_coder\n",
            "creating build/lib.linux-x86_64-cpython-311/cbench/nn/utils\n",
            "copying cbench/nn/utils/__init__.py -> build/lib.linux-x86_64-cpython-311/cbench/nn/utils\n",
            "copying cbench/nn/utils/flop_counter.py -> build/lib.linux-x86_64-cpython-311/cbench/nn/utils\n",
            "copying cbench/nn/utils/batched_cross_entropy.py -> build/lib.linux-x86_64-cpython-311/cbench/nn/utils\n",
            "creating build/lib.linux-x86_64-cpython-311/cbench/nn/layers\n",
            "copying cbench/nn/layers/__init__.py -> build/lib.linux-x86_64-cpython-311/cbench/nn/layers\n",
            "copying cbench/nn/layers/slimmable_layers.py -> build/lib.linux-x86_64-cpython-311/cbench/nn/layers\n",
            "copying cbench/nn/layers/attention.py -> build/lib.linux-x86_64-cpython-311/cbench/nn/layers\n",
            "copying cbench/nn/layers/param_generator.py -> build/lib.linux-x86_64-cpython-311/cbench/nn/layers\n",
            "copying cbench/nn/layers/perceptual_output_layer.py -> build/lib.linux-x86_64-cpython-311/cbench/nn/layers\n",
            "copying cbench/nn/layers/entroformer_layers.py -> build/lib.linux-x86_64-cpython-311/cbench/nn/layers\n",
            "copying cbench/nn/layers/basic.py -> build/lib.linux-x86_64-cpython-311/cbench/nn/layers\n",
            "copying cbench/nn/layers/pgm_layers.py -> build/lib.linux-x86_64-cpython-311/cbench/nn/layers\n",
            "copying cbench/nn/layers/masked_conv.py -> build/lib.linux-x86_64-cpython-311/cbench/nn/layers\n",
            "copying cbench/nn/layers/spatial_frequency_adaption.py -> build/lib.linux-x86_64-cpython-311/cbench/nn/layers\n",
            "creating build/lib.linux-x86_64-cpython-311/cbench/nn/layers/survae\n",
            "copying cbench/nn/layers/survae/__init__.py -> build/lib.linux-x86_64-cpython-311/cbench/nn/layers/survae\n",
            "copying cbench/nn/layers/survae/transforms.py -> build/lib.linux-x86_64-cpython-311/cbench/nn/layers/survae\n",
            "copying cbench/nn/layers/survae/distributions.py -> build/lib.linux-x86_64-cpython-311/cbench/nn/layers/survae\n",
            "copying cbench/nn/layers/survae/argmax_coupling_flow.py -> build/lib.linux-x86_64-cpython-311/cbench/nn/layers/survae\n",
            "creating build/lib.linux-x86_64-cpython-311/cbench/nn/layers/mcquic_layers\n",
            "copying cbench/nn/layers/mcquic_layers/__init__.py -> build/lib.linux-x86_64-cpython-311/cbench/nn/layers/mcquic_layers\n",
            "copying cbench/nn/layers/mcquic_layers/models.py -> build/lib.linux-x86_64-cpython-311/cbench/nn/layers/mcquic_layers\n",
            "copying cbench/nn/layers/mcquic_layers/base.py -> build/lib.linux-x86_64-cpython-311/cbench/nn/layers/mcquic_layers\n",
            "copying cbench/nn/layers/mcquic_layers/blocks.py -> build/lib.linux-x86_64-cpython-311/cbench/nn/layers/mcquic_layers\n",
            "copying cbench/nn/layers/mcquic_layers/gdn.py -> build/lib.linux-x86_64-cpython-311/cbench/nn/layers/mcquic_layers\n",
            "copying cbench/nn/layers/mcquic_layers/convs.py -> build/lib.linux-x86_64-cpython-311/cbench/nn/layers/mcquic_layers\n",
            "running build_ext\n",
            "x86_64-linux-gnu-g++ -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/usr/include/python3.11 -c flagcheck.cpp -o flagcheck.o -std=c++17\n",
            "building 'cbench.rans' extension\n",
            "creating build/temp.linux-x86_64-cpython-311/cbench/csrc/rans\n",
            "x86_64-linux-gnu-g++ -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -Icbench/csrc/rans -I/usr/local/lib/python3.11/dist-packages/pybind11/include -I/usr/include/python3.11 -c cbench/csrc/rans/rans_interface.cpp -o build/temp.linux-x86_64-cpython-311/cbench/csrc/rans/rans_interface.o -std=c++17 -fvisibility=hidden -g0 -std=c++17 -g\n",
            "x86_64-linux-gnu-g++ -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -shared -Wl,-O1 -Wl,-Bsymbolic-functions build/temp.linux-x86_64-cpython-311/cbench/csrc/rans/rans_interface.o -L/usr/lib/x86_64-linux-gnu -o build/lib.linux-x86_64-cpython-311/cbench/rans.cpython-311-x86_64-linux-gnu.so\n",
            "building 'cbench.ar' extension\n",
            "creating build/temp.linux-x86_64-cpython-311/cbench/csrc/ar\n",
            "x86_64-linux-gnu-g++ -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -Icbench/csrc/ar -I/usr/local/lib/python3.11/dist-packages/pybind11/include -I/usr/include/python3.11 -c cbench/csrc/ar/ar.cpp -o build/temp.linux-x86_64-cpython-311/cbench/csrc/ar/ar.o -std=c++17 -fvisibility=hidden -g0 -std=c++17 -g\n",
            "x86_64-linux-gnu-g++ -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -shared -Wl,-O1 -Wl,-Bsymbolic-functions build/temp.linux-x86_64-cpython-311/cbench/csrc/ar/ar.o -L/usr/lib/x86_64-linux-gnu -o build/lib.linux-x86_64-cpython-311/cbench/ar.cpython-311-x86_64-linux-gnu.so\n",
            "building 'cbench.ans' extension\n",
            "creating build/temp.linux-x86_64-cpython-311/cbench/csrc/ans\n",
            "x86_64-linux-gnu-g++ -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -Icbench/csrc/ans -I/usr/local/lib/python3.11/dist-packages/pybind11/include -I/usr/include/python3.11 -c cbench/csrc/ans/ans_interface.cpp -o build/temp.linux-x86_64-cpython-311/cbench/csrc/ans/ans_interface.o -std=c++17 -fvisibility=hidden -g0 -std=c++17 -g\n",
            "x86_64-linux-gnu-g++ -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -Icbench/csrc/ans -I/usr/local/lib/python3.11/dist-packages/pybind11/include -I/usr/include/python3.11 -c cbench/csrc/ans/lib.cpp -o build/temp.linux-x86_64-cpython-311/cbench/csrc/ans/lib.o -std=c++17 -fvisibility=hidden -g0 -std=c++17 -g\n",
            "x86_64-linux-gnu-g++ -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -Icbench/csrc/ans -I/usr/local/lib/python3.11/dist-packages/pybind11/include -I/usr/include/python3.11 -c cbench/csrc/ans/rans64.cpp -o build/temp.linux-x86_64-cpython-311/cbench/csrc/ans/rans64.o -std=c++17 -fvisibility=hidden -g0 -std=c++17 -g\n",
            "x86_64-linux-gnu-g++ -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -Icbench/csrc/ans -I/usr/local/lib/python3.11/dist-packages/pybind11/include -I/usr/include/python3.11 -c cbench/csrc/ans/tans.cpp -o build/temp.linux-x86_64-cpython-311/cbench/csrc/ans/tans.o -std=c++17 -fvisibility=hidden -g0 -std=c++17 -g\n",
            "x86_64-linux-gnu-g++ -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -shared -Wl,-O1 -Wl,-Bsymbolic-functions build/temp.linux-x86_64-cpython-311/cbench/csrc/ans/ans_interface.o build/temp.linux-x86_64-cpython-311/cbench/csrc/ans/lib.o build/temp.linux-x86_64-cpython-311/cbench/csrc/ans/rans64.o build/temp.linux-x86_64-cpython-311/cbench/csrc/ans/tans.o -L/usr/lib/x86_64-linux-gnu -o build/lib.linux-x86_64-cpython-311/cbench/ans.cpython-311-x86_64-linux-gnu.so\n",
            "running develop\n",
            "running egg_info\n",
            "creating cbench.egg-info\n",
            "writing cbench.egg-info/PKG-INFO\n",
            "writing dependency_links to cbench.egg-info/dependency_links.txt\n",
            "writing top-level names to cbench.egg-info/top_level.txt\n",
            "writing manifest file 'cbench.egg-info/SOURCES.txt'\n",
            "reading manifest file 'cbench.egg-info/SOURCES.txt'\n",
            "writing manifest file 'cbench.egg-info/SOURCES.txt'\n",
            "running build_ext\n",
            "copying build/lib.linux-x86_64-cpython-311/cbench/rans.cpython-311-x86_64-linux-gnu.so -> cbench\n",
            "copying build/lib.linux-x86_64-cpython-311/cbench/ar.cpython-311-x86_64-linux-gnu.so -> cbench\n",
            "copying build/lib.linux-x86_64-cpython-311/cbench/ans.cpython-311-x86_64-linux-gnu.so -> cbench\n",
            "Creating /usr/local/lib/python3.11/dist-packages/cbench.egg-link (link to .)\n",
            "Adding cbench 0.2 to easy-install.pth file\n",
            "\n",
            "Installed /content/cbench_BaSIC\n",
            "Processing dependencies for cbench==0.2\n",
            "Finished processing dependencies for cbench==0.2\n",
            "Try import cbench.rans\n",
            "Import cbench.rans success!\n",
            "Try import cbench.ar\n",
            "Import cbench.ar success!\n",
            "Try import cbench.ans\n",
            "Import cbench.ans success!\n",
            "Setup success!\n",
            "\n",
            "cbench from: /content/cbench_BaSIC/cbench/__init__.py\n",
            "oss2 not installed! Disabling OSSUtils!\n",
            "✅ Layers OK: <class 'cbench.nn.layers.slimmable_layers.DynamicConv2d'> <class 'cbench.nn.layers.slimmable_layers.DynamicGDN'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# slimcae_wrapper.py\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from cbench.nn.layers.slimmable_layers import (\n",
        "    DynamicConv2d, DynamicGDN,\n",
        "    DynamicResidualBlock, DynamicResidualBlockUpsample\n",
        ")\n",
        "\n",
        "class SlimCAE(nn.Module):\n",
        "    def __init__(self, channels_list=(64, 96, 128)):\n",
        "        super().__init__()\n",
        "        C = list(channels_list)            # e.g., [64, 96, 128]\n",
        "        C_out3 = [3] * len(C)              # IMPORTANT: same length as the number of slim levels\n",
        "\n",
        "        # Encoder\n",
        "        self.enc = nn.Sequential(\n",
        "            DynamicConv2d(3, C, 5, 2, None, bias=True),\n",
        "            DynamicGDN(C),\n",
        "            DynamicResidualBlock(C[-1], C),\n",
        "            DynamicConv2d(C, C, 5, 2, None, bias=True),\n",
        "            DynamicGDN(C),\n",
        "        )\n",
        "\n",
        "        # Decoder\n",
        "        self.dec = nn.Sequential(\n",
        "            DynamicResidualBlockUpsample(C[-1], C, upsample=2),\n",
        "            DynamicResidualBlock(C[-1], C),\n",
        "            DynamicConv2d(C, C_out3, 5, 1, None, bias=True),  # NOTE: out-channels must be a list here\n",
        "        )\n",
        "\n",
        "    def set_level(self, level: int):\n",
        "        # Propagate the selected slim level to all dynamic modules\n",
        "        for m in self.modules():\n",
        "            if hasattr(m, \"set_complex_level\"):\n",
        "                m.set_complex_level(level)\n",
        "\n",
        "    def forward(self, x):\n",
        "        z = self.enc(x)\n",
        "        y = self.dec(z)\n",
        "        return y, z\n",
        "\n"
      ],
      "metadata": {
        "id": "XVciPV7ogEOV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = SlimCAE((64,96,128))\n",
        "net.set_level(1)\n",
        "out, z = net(torch.randn(1,3,256,256))\n",
        "print(out.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KKKHAAP5gGGQ",
        "outputId": "850a77b1-2d04-4ad0-fc9f-dc20538ff5e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 3, 128, 128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This revised SlimCAE class ensures the output image has the same spatial dimensions as the input image (e.g., 256x256)."
      ],
      "metadata": {
        "id": "bgbXrZScwQRh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# slimcae_wrapper.py (Corrected)\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from cbench.nn.layers.slimmable_layers import (\n",
        "    DynamicConv2d, DynamicGDN,\n",
        "    DynamicResidualBlock, DynamicResidualBlockUpsample\n",
        ")\n",
        "\n",
        "class SlimCAE(nn.Module):\n",
        "    \"\"\"\n",
        "    Corrected Slimmable Convolutional Autoencoder (SlimCAE).\n",
        "\n",
        "    This version has a symmetric encoder-decoder architecture, ensuring the\n",
        "    reconstructed image has the same dimensions as the input.\n",
        "    \"\"\"\n",
        "    def __init__(self, channels_list=(64, 96, 128)):\n",
        "        super().__init__()\n",
        "        # Ensure channels_list is a list\n",
        "        C = list(channels_list)\n",
        "        # Output channels for the final layer (always 3 for an RGB image)\n",
        "        C_out3 = [3] * len(C)\n",
        "\n",
        "        # Encoder: Downsamples the input image by a factor of 4\n",
        "        self.enc = nn.Sequential(\n",
        "            DynamicConv2d(3, C, kernel_size=5, stride=2, groups_list=None, bias=True),\n",
        "            DynamicGDN(C),\n",
        "            DynamicConv2d(C, C, kernel_size=5, stride=2, groups_list=None, bias=True),\n",
        "            DynamicGDN(C),\n",
        "        )\n",
        "\n",
        "        # Decoder: Upsamples the latent representation back to the original image size\n",
        "        self.dec = nn.Sequential(\n",
        "            DynamicGDN(C, inverse=True),\n",
        "            # The `in_channels` argument for dynamic blocks is typically the max channel count\n",
        "            DynamicResidualBlockUpsample(C[-1], C, upsample=2),\n",
        "            DynamicGDN(C, inverse=True),\n",
        "            DynamicResidualBlockUpsample(C[-1], C_out3, upsample=2),\n",
        "        )\n",
        "\n",
        "    def set_level(self, level: int):\n",
        "        \"\"\"\n",
        "        Sets the complexity level for all dynamic modules in the network.\n",
        "        Level 0 is the smallest model, and level n-1 is the largest.\n",
        "        \"\"\"\n",
        "        for m in self.modules():\n",
        "            if hasattr(m, \"set_complex_level\"):\n",
        "                m.set_complex_level(level)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass through the autoencoder.\n",
        "        \"\"\"\n",
        "        # z is the latent representation\n",
        "        z = self.enc(x)\n",
        "        # y is the reconstructed image\n",
        "        y = self.dec(z)\n",
        "        return y, z\n",
        "\n",
        "# --- Verification Step ---\n",
        "# Create a sample input tensor\n",
        "test_net = SlimCAE((64, 96, 128))\n",
        "test_net.set_level(2) # Set to the largest model\n",
        "test_input = torch.randn(1, 3, 256, 256)\n",
        "\n",
        "# Pass the input through the model\n",
        "reconstruction, latent = test_net(test_input)\n",
        "\n",
        "# Check if the output shape matches the input shape\n",
        "print(f\"Input shape: {test_input.shape}\")\n",
        "print(f\"Latent shape: {latent.shape}\")\n",
        "print(f\"Reconstruction shape: {reconstruction.shape}\")\n",
        "assert reconstruction.shape == test_input.shape\n",
        "print(\"✅ Model architecture verified successfully!\")"
      ],
      "metadata": {
        "id": "QG_Z09M5wMON"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This cell sets up all the necessary components for training: hyperparameters, device configuration, and data loaders. We will use the CIFAR-10 dataset from torchvision and resize the images to 256x256 to work with the model's architecture."
      ],
      "metadata": {
        "id": "91Q0xLIKwbiF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# --- Configuration & Hyperparameters ---\n",
        "CONFIG = {\n",
        "    \"epochs\": 10,\n",
        "    \"batch_size\": 16,\n",
        "    \"learning_rate\": 1e-4,\n",
        "    \"lambda_rate\": 1e-2, # Weight for the rate term in the loss function\n",
        "    \"num_levels\": 3, # Corresponds to channels_list=(64, 96, 128)\n",
        "    \"channels_list\": (64, 96, 128),\n",
        "    \"val_split\": 0.1, # 10% of training data for validation\n",
        "}\n",
        "\n",
        "# --- Device Setup ---\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "\n",
        "# --- Data Preparation ---\n",
        "# Define transformations: Resize, convert to tensor, and normalize\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "# Download and load the full CIFAR-10 training dataset\n",
        "full_train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                                  download=True, transform=transform)\n",
        "\n",
        "# Split training data into training and validation sets\n",
        "num_train = len(full_train_dataset)\n",
        "indices = list(range(num_train))\n",
        "split = int(np.floor(CONFIG[\"val_split\"] * num_train))\n",
        "np.random.shuffle(indices)\n",
        "train_idx, val_idx = indices[split:], indices[:split]\n",
        "\n",
        "train_sampler = torch.utils.data.SubsetRandomSampler(train_idx)\n",
        "val_sampler = torch.utils.data.SubsetRandomSampler(val_idx)\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = DataLoader(full_train_dataset, batch_size=CONFIG[\"batch_size\"], sampler=train_sampler, num_workers=2)\n",
        "val_loader = DataLoader(full_train_dataset, batch_size=CONFIG[\"batch_size\"], sampler=val_sampler, num_workers=2)\n",
        "\n",
        "# Load the test dataset\n",
        "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                                 download=True, transform=transform)\n",
        "test_loader = DataLoader(test_dataset, batch_size=CONFIG[\"batch_size\"], shuffle=False, num_workers=2)\n",
        "\n",
        "print(\"Data loaders created successfully.\")"
      ],
      "metadata": {
        "id": "HjKMmwJ4wbvS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training and Evaluation"
      ],
      "metadata": {
        "id": "H9GtZ2rDwftp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "import math\n",
        "\n",
        "def rate_distortion_loss(reconstruction, original, latent, lambda_rate):\n",
        "    \"\"\"\n",
        "    Calculates the rate-distortion loss.\n",
        "    L = Distortion + lambda * Rate\n",
        "    \"\"\"\n",
        "    # Distortion: Mean Squared Error\n",
        "    mse = F.mse_loss(reconstruction, original)\n",
        "\n",
        "    # Rate: A simple estimate of bits per pixel (BPP).\n",
        "    # We model the latent distribution as a zero-mean Gaussian and calculate\n",
        "    # its entropy. A lower entropy means a more compressible representation.\n",
        "    # This is a common proxy for the actual bitrate.\n",
        "    bpp = torch.mean(torch.log2(1 + latent.pow(2)))\n",
        "\n",
        "    # Total Loss\n",
        "    total_loss = mse + lambda_rate * bpp\n",
        "\n",
        "    return total_loss, mse, bpp\n",
        "\n",
        "def train_one_epoch(model, dataloader, optimizer, epoch, num_levels, lambda_rate, device):\n",
        "    model.train()\n",
        "    progress_bar = tqdm(dataloader, desc=f\"Epoch {epoch+1}\")\n",
        "    total_loss_avg = 0\n",
        "\n",
        "    for i, (images, _) in enumerate(progress_bar):\n",
        "        images = images.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        total_loss_batch = 0\n",
        "\n",
        "        # --- Sandwich Rule: Train on all complexity levels ---\n",
        "        for level in range(num_levels):\n",
        "            model.set_level(level)\n",
        "            reconstruction, latent = model(images)\n",
        "            loss, mse, bpp = rate_distortion_loss(reconstruction, images, latent, lambda_rate)\n",
        "            total_loss_batch += loss\n",
        "\n",
        "        # Average the loss over all levels and backpropagate\n",
        "        avg_loss = total_loss_batch / num_levels\n",
        "        avg_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss_avg += avg_loss.item()\n",
        "        progress_bar.set_postfix(loss=f\"{total_loss_avg / (i+1):.4f}\")\n",
        "\n",
        "    return total_loss_avg / len(dataloader)\n",
        "\n",
        "\n",
        "def evaluate(model, dataloader, num_levels, lambda_rate, device):\n",
        "    model.eval()\n",
        "    # Dictionaries to store metrics for each level\n",
        "    losses, mses, bpps, psnrs = [0]*num_levels, [0]*num_levels, [0]*num_levels, [0]*num_levels\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, _ in dataloader:\n",
        "            images = images.to(device)\n",
        "\n",
        "            for level in range(num_levels):\n",
        "                model.set_level(level)\n",
        "                reconstruction, latent = model(images)\n",
        "                loss, mse, bpp = rate_distortion_loss(reconstruction, images, latent, lambda_rate)\n",
        "\n",
        "                # Accumulate metrics\n",
        "                losses[level] += loss.item()\n",
        "                mses[level] += mse.item()\n",
        "                bpps[level] += bpp.item()\n",
        "                # Calculate PSNR from MSE\n",
        "                psnrs[level] += 20 * math.log10(1.0 / math.sqrt(mse.item()))\n",
        "\n",
        "    # Average the metrics over the dataset\n",
        "    num_batches = len(dataloader)\n",
        "    results = []\n",
        "    for level in range(num_levels):\n",
        "        results.append({\n",
        "            \"level\": level,\n",
        "            \"loss\": losses[level] / num_batches,\n",
        "            \"mse\": mses[level] / num_batches,\n",
        "            \"bpp\": bpps[level] / num_batches,\n",
        "            \"psnr\": psnrs[level] / num_batches,\n",
        "        })\n",
        "\n",
        "    return results"
      ],
      "metadata": {
        "id": "OSfRpNdLwfyP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Main Execution and Visualization"
      ],
      "metadata": {
        "id": "dSPS6RMqwrVR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Initialization ---\n",
        "model = SlimCAE(channels_list=CONFIG[\"channels_list\"]).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=CONFIG[\"learning_rate\"])\n",
        "train_losses = []\n",
        "val_results_history = []\n",
        "\n",
        "# --- Training Loop ---\n",
        "for epoch in range(CONFIG[\"epochs\"]):\n",
        "    # Train for one epoch\n",
        "    train_loss = train_one_epoch(\n",
        "        model, train_loader, optimizer, epoch,\n",
        "        CONFIG[\"num_levels\"], CONFIG[\"lambda_rate\"], device\n",
        "    )\n",
        "    train_losses.append(train_loss)\n",
        "\n",
        "    # Evaluate on the validation set\n",
        "    val_results = evaluate(\n",
        "        model, val_loader, CONFIG[\"num_levels\"], CONFIG[\"lambda_rate\"], device\n",
        "    )\n",
        "    val_results_history.append(val_results)\n",
        "\n",
        "    # Print summary\n",
        "    print(f\"\\n--- Epoch {epoch+1} Validation Results ---\")\n",
        "    for res in val_results:\n",
        "        print(f\"Level {res['level']}: Loss={res['loss']:.4f}, PSNR={res['psnr']:.2f} dB, BPP={res['bpp']:.4f}\")\n",
        "    print(\"-\" * 35)\n",
        "\n",
        "\n",
        "print(\"\\n✅ Training finished.\")\n",
        "\n",
        "# --- Final Testing ---\n",
        "print(\"\\nRunning final evaluation on the test set...\")\n",
        "test_results = evaluate(model, test_loader, CONFIG[\"num_levels\"], CONFIG[\"lambda_rate\"], device)\n",
        "\n",
        "print(\"\\n--- Final Test Results ---\")\n",
        "for res in test_results:\n",
        "    print(f\"Level {res['level']} (Channels: {CONFIG['channels_list'][res['level']]}): PSNR={res['psnr']:.2f} dB, BPP={res['bpp']:.4f}\")\n",
        "print(\"-\" * 28)\n",
        "\n",
        "\n",
        "# --- Visualization ---\n",
        "# 1. Plot training loss\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(train_losses)\n",
        "plt.title(\"Average Training Loss vs. Epochs\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.grid(True)\n",
        "\n",
        "# 2. Plot Rate-Distortion-Complexity Tradeoff\n",
        "plt.subplot(1, 2, 2)\n",
        "colors = ['blue', 'green', 'red']\n",
        "for level in range(CONFIG[\"num_levels\"]):\n",
        "    psnr = test_results[level]['psnr']\n",
        "    bpp = test_results[level]['bpp']\n",
        "    channels = CONFIG['channels_list'][level]\n",
        "    plt.scatter(bpp, psnr, color=colors[level], label=f'Level {level} ({channels} channels)', s=100)\n",
        "\n",
        "plt.title(\"Rate-Distortion-Complexity Tradeoff (Test Set)\")\n",
        "plt.xlabel(\"Rate (BPP)\")\n",
        "plt.ylabel(\"Distortion (PSNR)\")\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 3. Visualize some reconstructions\n",
        "model.eval()\n",
        "images, _ = next(iter(test_loader))\n",
        "images = images[:4].to(device) # Take 4 images\n",
        "\n",
        "fig, axes = plt.subplots(CONFIG['num_levels'], 5, figsize=(15, 8))\n",
        "fig.suptitle(\"Original vs. Reconstructions at Different Complexity Levels\")\n",
        "for i in range(4):\n",
        "    axes[0, i+1].imshow(images[i].cpu().permute(1, 2, 0) * 0.5 + 0.5)\n",
        "    axes[0, i+1].set_title(f\"Original {i+1}\")\n",
        "    axes[0, i+1].axis('off')\n",
        "\n",
        "for level in range(CONFIG['num_levels']):\n",
        "    model.set_level(level)\n",
        "    reconstructions, _ = model(images)\n",
        "    axes[level, 0].text(0.5, 0.5, f\"Level {level}\", ha='center', va='center', fontsize=12)\n",
        "    axes[level, 0].axis('off')\n",
        "\n",
        "    for i in range(4):\n",
        "        axes[level, i+1].imshow(reconstructions[i].cpu().detach().permute(1, 2, 0) * 0.5 + 0.5)\n",
        "        axes[level, i+1].axis('off')\n",
        "\n",
        "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mJmg9LzOwran"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Todo: Rate Distortion Complexity Trade Off"
      ],
      "metadata": {
        "id": "fWJQHgbMg3Ad"
      }
    }
  ]
}