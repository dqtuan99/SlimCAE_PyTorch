{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Slimmable Compressive Autoencoders (SlimCAE) in PyTorch\n",
    "\n",
    "This notebook is an adaptation of the original `SlimCAE_PyTorch.py` script for execution in Google Colab. It handles all dependencies, mounts Google Drive for data and model storage, and provides interactive cells to run training, fine-tuning, and evaluation.\n",
    "\n",
    "### Original Paper: [[paper]](https://arxiv.org/abs/2103.15726)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup Environment\n",
    "\n",
    "This section installs dependencies, mounts your Google Drive, and unzips your datasets into the local Colab environment for fast access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install all required packages\n",
    "# We use -q to make the output quieter.\n",
    "# Upgraded matplotlib to >=3.8.0 to resolve dependency conflicts with pre-installed Colab packages (arviz, plotnine).\n",
    "!pip install -q compressai==1.2.6 \\\n",
    "    matplotlib>=3.8.0 \\\n",
    "    numpy==1.23.5 \\\n",
    "    Pillow==9.5.0 \\\n",
    "    pytorch_msssim==0.2.1 \\\n",
    "    tqdm==4.66.1\n",
    "\n",
    "# Install PyTorch separately as it has a specific index URL\n",
    "!pip install -q torch==2.1.0+cu118 torchvision==0.16.0+cu118 --index-url https://download.pytorch.org/whl/cu118\n",
    "\n",
    "print(\"✅ Dependencies installed successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important: Prepare Your Google Drive Folders\n",
    "\n",
    "Before proceeding, please ensure you have the following folder structure in your Google Drive. This notebook is configured to work with these paths.\n",
    "\n",
    "```\n",
    "/content/drive/MyDrive/SlimCAE/\n",
    "├── datasets/            # Your zipped datasets go here\n",
    "│   ├── train.zip\n",
    "│   └── test.zip\n",
    "├── checkpoints_torch/     # Your pretrained models go here\n",
    "│   ├── checkpoint_1000000.pth\n",
    "│   └── final_scheduled_model.pth\n",
    "└── evaluation_torch/      # Evaluation reports will be saved here\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "from google.colab import drive\n",
    "\n",
    "# Mount Google Drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# --- Unzip Datasets for Faster Access ---\n",
    "# This copies the datasets from Drive to the local Colab machine.\n",
    "# It dramatically speeds up training by avoiding slow Drive I/O.\n",
    "\n",
    "GDRIVE_BASE_PATH = \"/content/drive/MyDrive/SlimCAE\"\n",
    "LOCAL_DATA_PATH = \"/content/dataset\"\n",
    "\n",
    "os.makedirs(LOCAL_DATA_PATH, exist_ok=True)\n",
    "\n",
    "print(\"Unzipping training data...\")\n",
    "with zipfile.ZipFile(f'{GDRIVE_BASE_PATH}/datasets/train.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall(f'{LOCAL_DATA_PATH}/train')\n",
    "\n",
    "print(\"Unzipping test data...\")\n",
    "with zipfile.ZipFile(f'{GDRIVE_BASE_PATH}/datasets/test.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall(f'{LOCAL_DATA_PATH}/test')\n",
    "\n",
    "print(\"\\nDatasets are ready at:\", LOCAL_DATA_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Core Code (Model, Data, and Training Logic)\n",
    "\n",
    "This cell contains all the Python code from the original `SlimCAE_PyTorch.py` script. It includes the model definition, custom layers, data loaders, and the training/evaluation functions. You can collapse this cell for better readability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "import glob\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from compressai.layers import GDN\n",
    "from compressai.entropy_models import EntropyBottleneck\n",
    "from pytorch_msssim import ms_ssim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# ==============================================================================\n",
    "# 1. CUSTOM DYNAMIC LAYERS\n",
    "# ==============================================================================\n",
    "\n",
    "class DynamicConv2d(nn.Module):\n",
    "    \"\"\" A dynamic 2D convolution layer that can switch between different channel configurations. \"\"\"\n",
    "    def __init__(self, in_channels_list, out_channels_list, kernel_size, stride=1, padding=0, bias=True):\n",
    "        super().__init__()\n",
    "        self.convs = nn.ModuleList([\n",
    "            nn.Conv2d(in_ch, out_ch, kernel_size, stride, padding, bias=bias)\n",
    "            for in_ch, out_ch in zip(in_channels_list, out_channels_list)\n",
    "        ])\n",
    "        self._active_level = 0\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.convs[self._active_level](x)\n",
    "\n",
    "    def set_active_level(self, level):\n",
    "        self._active_level = level\n",
    "\n",
    "class DynamicConvTranspose2d(nn.Module):\n",
    "    \"\"\" A dynamic 2D transposed convolution layer. \"\"\"\n",
    "    def __init__(self, in_channels_list, out_channels_list, kernel_size, stride=1, padding=0, output_padding=0, bias=True):\n",
    "        super().__init__()\n",
    "        self.convs = nn.ModuleList([\n",
    "            nn.ConvTranspose2d(in_ch, out_ch, kernel_size, stride, padding, output_padding, bias=bias)\n",
    "            for in_ch, out_ch in zip(in_channels_list, out_channels_list)\n",
    "        ])\n",
    "        self._active_level = 0\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.convs[self._active_level](x)\n",
    "\n",
    "    def set_active_level(self, level):\n",
    "        self._active_level = level\n",
    "\n",
    "# ==============================================================================\n",
    "# 2. DATA HANDLING\n",
    "# ==============================================================================\n",
    "\n",
    "def get_padding(h, w, p=64):\n",
    "    \"\"\" Calculates padding for a given height and width to make them divisible by p. \"\"\"\n",
    "    new_h = (h + p - 1) // p * p\n",
    "    new_w = (w + p - 1) // p * p\n",
    "    padding_left = (new_w - w) // 2\n",
    "    padding_right = new_w - w - padding_left\n",
    "    padding_top = (new_h - h) // 2\n",
    "    padding_bottom = new_h - h - padding_top\n",
    "    return padding_left, padding_right, padding_top, padding_bottom\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    \"\"\" A simple dataset to load images from a folder. \"\"\"\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.image_files = []\n",
    "        extensions = [\"*.png\", \"*.jpg\", \"*.jpeg\"]\n",
    "        for ext in extensions:\n",
    "            self.image_files.extend(glob.glob(os.path.join(root_dir, ext)))\n",
    "\n",
    "        if not self.image_files:\n",
    "            print(f\"Warning: No images found in {root_dir} with extensions {extensions}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_files[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image\n",
    "\n",
    "# ==============================================================================\n",
    "# 3. MODEL DEFINITION\n",
    "# ==============================================================================\n",
    "\n",
    "class SlimCAE_TF_Matched(nn.Module):\n",
    "    \"\"\"\n",
    "    Slimmable Compressive Autoencoder with an architecture that closely matches\n",
    "    the provided TensorFlow implementation.\n",
    "    \"\"\"\n",
    "    def __init__(self, total_filters=128, switch_list=(128, 96, 64)):\n",
    "        super().__init__()\n",
    "        self.total_filters = total_filters\n",
    "        self.switch_list = switch_list\n",
    "        self.num_levels = len(switch_list)\n",
    "\n",
    "        # --- ENCODER ---\n",
    "        self.enc_layer_0 = DynamicConv2d([3] * self.num_levels, switch_list, kernel_size=9, stride=4, padding=4, bias=True)\n",
    "        self.gdn_an_0 = nn.ModuleList([GDN(ch) for ch in switch_list])\n",
    "        \n",
    "        self.enc_layer_1 = DynamicConv2d([self.total_filters] * self.num_levels, switch_list, kernel_size=5, stride=2, padding=2, bias=True)\n",
    "        self.gdn_an_1 = nn.ModuleList([GDN(ch) for ch in switch_list])\n",
    "\n",
    "        self.enc_layer_2 = DynamicConv2d([self.total_filters] * self.num_levels, switch_list, kernel_size=5, stride=2, padding=2, bias=False)\n",
    "        self.gdn_an_2 = nn.ModuleList([GDN(ch) for ch in switch_list])\n",
    "\n",
    "        # --- DECODER ---\n",
    "        self.igdn_sy_0 = nn.ModuleList([GDN(ch, inverse=True) for ch in switch_list])\n",
    "        self.dec_layer_0 = DynamicConvTranspose2d([self.total_filters] * self.num_levels, [self.total_filters] * self.num_levels, kernel_size=5, stride=2, padding=2, output_padding=1, bias=True)\n",
    "\n",
    "        self.igdn_sy_1 = nn.ModuleList([GDN(self.total_filters, inverse=True) for _ in switch_list])\n",
    "        self.dec_layer_1 = DynamicConvTranspose2d([self.total_filters] * self.num_levels, [self.total_filters] * self.num_levels, kernel_size=5, stride=2, padding=2, output_padding=1, bias=True)\n",
    "        \n",
    "        self.igdn_sy_2 = nn.ModuleList([GDN(self.total_filters, inverse=True) for _ in switch_list])\n",
    "        self.dec_layer_2 = DynamicConvTranspose2d([self.total_filters] * self.num_levels, [3] * self.num_levels, kernel_size=9, stride=4, padding=4, output_padding=3, bias=True)\n",
    "\n",
    "        self.entropy_bottlenecks = nn.ModuleList([\n",
    "            EntropyBottleneck(channels) for channels in switch_list\n",
    "        ])\n",
    "\n",
    "    def forward(self, x):\n",
    "        reconstructions, likelihoods_list = [], []\n",
    "\n",
    "        for i in range(self.num_levels):\n",
    "            _switch = self.switch_list[i]\n",
    "            \n",
    "            for module in self.modules():\n",
    "                if hasattr(module, 'set_active_level'):\n",
    "                    module.set_active_level(i)\n",
    "\n",
    "            y = self.enc_layer_0(x)\n",
    "            y = self.gdn_an_0[i](y)\n",
    "            y = F.pad(y, (0, 0, 0, 0, 0, self.total_filters - _switch))\n",
    "\n",
    "            y = self.enc_layer_1(y)\n",
    "            y = self.gdn_an_1[i](y)\n",
    "            y = F.pad(y, (0, 0, 0, 0, 0, self.total_filters - _switch))\n",
    "\n",
    "            y = self.enc_layer_2(y)\n",
    "            y = self.gdn_an_2[i](y)\n",
    "            \n",
    "            y_hat, likelihoods = self.entropy_bottlenecks[i](y)\n",
    "            likelihoods_list.append(likelihoods)\n",
    "            \n",
    "            x_hat = self.igdn_sy_0[i](y_hat)\n",
    "            x_hat = F.pad(x_hat, (0, 0, 0, 0, 0, self.total_filters - _switch))\n",
    "            \n",
    "            x_hat = self.dec_layer_0(x_hat)\n",
    "            x_hat = self.igdn_sy_1[i](x_hat)\n",
    "            \n",
    "            x_hat = self.dec_layer_1(x_hat)\n",
    "            x_hat = self.igdn_sy_2[i](x_hat)\n",
    "            \n",
    "            x_hat = self.dec_layer_2(x_hat)\n",
    "            \n",
    "            reconstructions.append(x_hat)\n",
    "\n",
    "        return reconstructions, likelihoods_list\n",
    "        \n",
    "# ==============================================================================\n",
    "# 4. CORE TRAINING AND EVALUATION LOGIC\n",
    "# ==============================================================================\n",
    "\n",
    "def rate_distortion_loss(reconstructions, original, likelihoods_list, lmbdas, num_pixels):\n",
    "    total_loss = 0\n",
    "    bpp_list, mse_list = [], []\n",
    "\n",
    "    for i in range(len(reconstructions)):\n",
    "        mse = F.mse_loss(reconstructions[i], original)\n",
    "        bpp = torch.log(likelihoods_list[i]).sum() / (-math.log(2) * num_pixels)\n",
    "        rd_loss = lmbdas[i] * (mse * 255**2) + bpp\n",
    "        total_loss += rd_loss\n",
    "        \n",
    "        bpp_list.append(bpp)\n",
    "        mse_list.append(mse)\n",
    "\n",
    "    return total_loss, bpp_list, mse_list\n",
    "\n",
    "def train_one_epoch(model, dataloader, optimizer, lmbdas, \n",
    "                    patch_size, device, start_step=0, writer=None, clip_max_norm=1.0):\n",
    "    model.train()\n",
    "    num_pixels = patch_size ** 2\n",
    "    current_step = start_step\n",
    "    \n",
    "    # Use tqdm for progress bar\n",
    "    pbar = tqdm(dataloader, desc=f\"Training (Step {start_step})\")\n",
    "    for images in pbar:\n",
    "        images = images.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        reconstructions, likelihoods_list = model(images)\n",
    "        \n",
    "        rd_loss, bpp_list, mse_list = rate_distortion_loss(\n",
    "            reconstructions, images, likelihoods_list, lmbdas, num_pixels\n",
    "        )\n",
    "        \n",
    "        aux_loss = sum(eb.loss() for eb in model.entropy_bottlenecks)\n",
    "        total_loss_for_backward = rd_loss + aux_loss\n",
    "        total_loss_for_backward.backward()\n",
    "        \n",
    "        if clip_max_norm > 0:\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), clip_max_norm)\n",
    "        \n",
    "        optimizer.step()\n",
    "        pbar.set_postfix(loss=f'{total_loss_for_backward.item():.4f}')\n",
    "\n",
    "        if current_step % 10 == 0 and writer is not None:\n",
    "            writer.add_scalar('Loss/rate_distortion', rd_loss.item(), current_step)\n",
    "            writer.add_scalar('Loss/auxiliary', aux_loss.item(), current_step)\n",
    "            writer.add_scalar('Loss/total', total_loss_for_backward.item(), current_step)\n",
    "            for i in range(len(bpp_list)):\n",
    "                writer.add_scalar(f'BPP/level_{i}', bpp_list[i].item(), current_step)\n",
    "                writer.add_scalar(f'MSE/level_{i}', mse_list[i].item() * 255**2, current_step)\n",
    "                \n",
    "        current_step += 1\n",
    "    return current_step\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, dataloader, device):\n",
    "    model.eval()\n",
    "    num_levels = model.num_levels\n",
    "    \n",
    "    bpp_avg = [0.0] * num_levels\n",
    "    psnr_avg = [0.0] * num_levels\n",
    "    mse_avg = [0.0] * num_levels\n",
    "    msssim_avg = [0.0] * num_levels\n",
    "    msssim_db_avg = [0.0] * num_levels\n",
    "    count = 0\n",
    "\n",
    "    for images in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "        images = images.to(device)\n",
    "        h, w = images.shape[2:]\n",
    "        num_pixels = h * w\n",
    "        \n",
    "        pad_l, pad_r, pad_t, pad_b = get_padding(h, w)\n",
    "        padded_images = F.pad(images, (pad_l, pad_r, pad_t, pad_b), mode=\"replicate\")\n",
    "        reconstructions, likelihoods_list = model(padded_images)\n",
    "        \n",
    "        for i in range(num_levels):\n",
    "            rec_i = reconstructions[i][..., pad_t:pad_t+h, pad_l:pad_l+w].clamp(0, 1)\n",
    "            bpp = torch.log(likelihoods_list[i]).sum() / (-math.log(2) * num_pixels)\n",
    "            mse = F.mse_loss(rec_i, images)\n",
    "            psnr = 10 * torch.log10(1.0 / mse)\n",
    "            msssim_val = ms_ssim(rec_i, images, data_range=1.0)\n",
    "            msssim_db = -10 * torch.log10(1 - msssim_val)\n",
    "            \n",
    "            bpp_avg[i] += bpp.item()\n",
    "            psnr_avg[i] += psnr.item()\n",
    "            mse_avg[i] += mse.item()\n",
    "            msssim_avg[i] += msssim_val.item()\n",
    "            msssim_db_avg[i] += msssim_db.item()\n",
    "        count += 1\n",
    "        \n",
    "    for i in range(num_levels):\n",
    "        bpp_avg[i] /= count\n",
    "        psnr_avg[i] /= count\n",
    "        mse_avg[i] /= count\n",
    "        msssim_avg[i] /= count\n",
    "        msssim_db_avg[i] /= count\n",
    "        \n",
    "    return bpp_avg, psnr_avg, mse_avg, msssim_avg, msssim_db_avg\n",
    "\n",
    "# ==============================================================================\n",
    "# 5. MAIN WORKFLOW FUNCTIONS\n",
    "# ==============================================================================\n",
    "\n",
    "def train_model(args, device):\n",
    "    print(\"Starting Stage 1: Initial model training.\")\n",
    "    \n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.Resize(args.patchsize),\n",
    "        transforms.RandomCrop(args.patchsize),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "    train_dataset = ImageDataset(root_dir=args.train_glob, transform=train_transform)\n",
    "    # Use pin_memory=True and more workers if GPU allows for faster data loading\n",
    "    train_loader = DataLoader(train_dataset, batch_size=args.batchsize, shuffle=True, num_workers=2, pin_memory=True)\n",
    "    \n",
    "    model = SlimCAE_TF_Matched(total_filters=args.num_filters, switch_list=args.switch_list).to(device)\n",
    "    \n",
    "    main_params = [p for n, p in model.named_parameters() if not n.endswith(\".quantiles\")]\n",
    "    aux_params = [p for n, p in model.named_parameters() if n.endswith(\".quantiles\")]\n",
    "    optimizer = optim.Adam(\n",
    "        [\n",
    "            {\"params\": main_params, \"lr\": 1e-4},\n",
    "            {\"params\": aux_params, \"lr\": 1e-3},\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    os.makedirs(args.checkpoint_dir, exist_ok=True)\n",
    "    \n",
    "    num_steps = 0\n",
    "    if args.resume:\n",
    "        try:\n",
    "            checkpoint_files = glob.glob(os.path.join(args.checkpoint_dir, \"checkpoint_*.pth\"))\n",
    "            if not checkpoint_files: raise FileNotFoundError\n",
    "\n",
    "            latest_ckpt_path = max(\n",
    "                checkpoint_files, \n",
    "                key=lambda f: int(\"\".join(filter(str.isdigit, os.path.basename(f))))\n",
    "            )\n",
    "            \n",
    "            print(f\"Resuming training from checkpoint: {latest_ckpt_path}\")\n",
    "            checkpoint = torch.load(latest_ckpt_path, map_location=device)\n",
    "            \n",
    "            model.load_state_dict(checkpoint['model_state_dict'])\n",
    "            optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "            num_steps = checkpoint['step']\n",
    "            args.lmbda = checkpoint['lmbda']\n",
    "\n",
    "        except (FileNotFoundError, KeyError, IndexError):\n",
    "            print(\"Could not find a valid checkpoint. Starting from scratch.\")\n",
    "            num_steps = 0\n",
    "\n",
    "    writer = SummaryWriter(log_dir=os.path.join(args.checkpoint_dir, 'tensorboard_logs'))\n",
    "    max_steps = args.last_step\n",
    "    \n",
    "    while num_steps < max_steps:\n",
    "        epoch = (num_steps // len(train_loader)) + 1\n",
    "        print(f\"\\n--- Training Epoch {epoch} (Step ~{num_steps}/{max_steps}) ---\")\n",
    "        \n",
    "        num_steps = train_one_epoch(\n",
    "            model, train_loader, optimizer, args.lmbda, \n",
    "            args.patchsize, device, start_step=num_steps, writer=writer\n",
    "        )\n",
    "\n",
    "        # Save checkpoint periodically\n",
    "        if num_steps > 0 and num_steps % 10000 < (num_steps - (num_steps - len(train_loader))):\n",
    "            checkpoint_path = os.path.join(args.checkpoint_dir, f\"checkpoint_{num_steps}.pth\")\n",
    "            torch.save({\n",
    "                'step': num_steps,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'lmbda': args.lmbda,\n",
    "            }, checkpoint_path)\n",
    "            print(f\"✅ Checkpoint saved to {checkpoint_path}\")\n",
    "\n",
    "    writer.close()\n",
    "    print(\"Stage 1 training finished.\")\n",
    "\n",
    "def train_lambda_schedule(args, device):\n",
    "    print(\"Starting Stage 2: Lambda scheduling.\")\n",
    "    \n",
    "    # Dataset for fine-tuning steps (uses training data)\n",
    "    fine_tune_transform = transforms.Compose([\n",
    "        transforms.Resize(args.patchsize),\n",
    "        transforms.RandomCrop(args.patchsize),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "    fine_tune_dataset = ImageDataset(root_dir=args.train_glob, transform=fine_tune_transform)\n",
    "    \n",
    "    # Dataset for evaluation steps (uses test data)\n",
    "    eval_transform = transforms.Compose([transforms.ToTensor()])\n",
    "    eval_dataset = ImageDataset(root_dir=args.inputPath, transform=eval_transform)\n",
    "    eval_loader = DataLoader(eval_dataset, batch_size=1, shuffle=False)\n",
    "    \n",
    "    model = SlimCAE_TF_Matched(total_filters=args.num_filters, switch_list=args.switch_list).to(device)\n",
    "    \n",
    "    main_params = [p for n, p in model.named_parameters() if not n.endswith(\".quantiles\")]\n",
    "    aux_params = [p for n, p in model.named_parameters() if n.endswith(\".quantiles\")]\n",
    "    optimizer = optim.Adam(\n",
    "        [\n",
    "            {\"params\": main_params, \"lr\": 1e-5}, # Lower LR for fine-tuning\n",
    "            {\"params\": aux_params, \"lr\": 1e-3},\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    checkpoint_files = glob.glob(os.path.join(args.checkpoint_dir, \"checkpoint_*.pth\"))\n",
    "    if not checkpoint_files: raise FileNotFoundError(\"No checkpoints found. Please run Stage 1 training first.\")\n",
    "    \n",
    "    latest_ckpt = max(checkpoint_files, key=lambda f: int(\"\".join(filter(str.isdigit, os.path.basename(f)))))\n",
    "    \n",
    "    print(f\"Loading checkpoint: {latest_ckpt}\")\n",
    "    checkpoint = torch.load(latest_ckpt, map_location=device)\n",
    "    \n",
    "    if 'model_state_dict' in checkpoint:\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    else:\n",
    "        model.load_state_dict(checkpoint)\n",
    "\n",
    "    if 'optimizer_state_dict' in checkpoint:\n",
    "        # We don't load the optimizer state as we are using a new learning rate\n",
    "        print(\"Optimizer state found in checkpoint, but re-initializing with fine-tuning learning rate.\")\n",
    "    \n",
    "    num_steps = checkpoint.get('step', 0)\n",
    "    lmbdas = list(args.lmbda)\n",
    "    \n",
    "    bpp, psnr, _, _, _ = evaluate(model, eval_loader, device)\n",
    "    \n",
    "    print(f\"Initial BPPs: {[f'{x:.4f}' for x in bpp]}, PSNRs: {[f'{x:.2f}' for x in psnr]}\")\n",
    "\n",
    "    for i in range(len(lmbdas) - 1):\n",
    "        print(f\"\\n--- Adjusting lambdas for level {i+1} and beyond ---\")\n",
    "        \n",
    "        if abs(bpp[i] - bpp[i+1]) < 1e-6: continue\n",
    "        grad_flag = (psnr[i] - psnr[i+1]) / (bpp[i] - bpp[i+1])\n",
    "        \n",
    "        m = 1\n",
    "        while m < 7:\n",
    "            for j in range(i + 1, len(lmbdas)):\n",
    "                lmbdas[j] *= 0.9\n",
    "            print(f\"Iteration {m}: New lambdas: {[f'{l:.4f}' for l in lmbdas]}\")\n",
    "\n",
    "            fine_tune_loader = DataLoader(fine_tune_dataset, batch_size=args.batchsize, shuffle=True)\n",
    "            for _ in range(5):\n",
    "                train_one_epoch(\n",
    "                    model, fine_tune_loader, optimizer, lmbdas, \n",
    "                    args.patchsize, device, start_step=0, clip_max_norm=0\n",
    "                )\n",
    "            \n",
    "            bpp, psnr, _, _, _ = evaluate(model, eval_loader, device)\n",
    "            print(f\"Re-evaluated BPPs: {[f'{x:.4f}' for x in bpp]}, PSNRs: {[f'{x:.2f}' for x in psnr]}\")\n",
    "\n",
    "            if abs(bpp[i] - bpp[i+1]) < 1e-6: break\n",
    "            grad_current = (psnr[i] - psnr[i+1]) / (bpp[i] - bpp[i+1])\n",
    "\n",
    "            print(f\"Slope check: Current grad={grad_current:.2f}, Target grad={grad_flag:.2f}\")\n",
    "            if grad_current > grad_flag:\n",
    "                print(\"✅ Slope improved. Moving to next level.\")\n",
    "                break\n",
    "            else:\n",
    "                grad_flag = grad_current\n",
    "                m += 1\n",
    "                if m >= 7: print(\"⚠️ Max iterations reached. Moving on.\")\n",
    "    \n",
    "    final_path = os.path.join(args.checkpoint_dir, \"final_scheduled_model.pth\")\n",
    "    torch.save({\n",
    "        'step': num_steps,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'lmbda': lmbdas,\n",
    "    }, final_path)\n",
    "    \n",
    "    print(f\"\\n--- Lambda Scheduling Complete. Final model saved to {final_path} ---\")\n",
    "    print(f\"Final optimized lambdas: {[f'{l:.4f}' for l in lmbdas]}\")\n",
    "\n",
    "def test_model(args, device):\n",
    "    num_models = len(args.checkpoint_paths)\n",
    "    if num_models not in [1, 2]:\n",
    "        raise ValueError(\"This script can only evaluate 1 or 2 models at a time. Please provide 1 or 2 paths to --checkpoint_paths.\")\n",
    "\n",
    "    print(\"Setting up dataset and model...\")\n",
    "    test_transform = transforms.Compose([transforms.ToTensor()])\n",
    "    test_dataset = ImageDataset(root_dir=args.inputPath, transform=test_transform)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "    \n",
    "    model = SlimCAE_TF_Matched(total_filters=args.num_filters, switch_list=args.switch_list).to(device)\n",
    "\n",
    "    if num_models == 1:\n",
    "        print(\"\\n--- Running Single-Model Evaluation ---\")\n",
    "        checkpoint_path = args.checkpoint_paths[0]\n",
    "        \n",
    "        print(f\"Loading checkpoint from: {checkpoint_path}\")\n",
    "        checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        \n",
    "        bpp, psnr, mse, msssim, msssim_db = evaluate(model, test_loader, device)\n",
    "        \n",
    "        print(\"\\n--- Final Test Results ---\")\n",
    "        for i in range(model.num_levels):\n",
    "            print(\n",
    "                f\"Level {i} (C={model.switch_list[i]}): \"\n",
    "                f\"BPP: {bpp[i]:.4f} | PSNR: {psnr[i]:.2f} dB | MSE: {mse[i]*255**2:.2f} | \"\n",
    "                f\"MS-SSIM: {msssim[i]:.4f} | MS-SSIM dB: {msssim_db[i]:.2f} dB\"\n",
    "            )\n",
    "\n",
    "        if args.report_path:\n",
    "            report_dir = os.path.dirname(args.report_path)\n",
    "            if report_dir: os.makedirs(report_dir, exist_ok=True)\n",
    "            report_file = args.report_path + \".csv\"\n",
    "            with open(report_file, 'w', newline='') as f:\n",
    "                writer = csv.writer(f)\n",
    "                header = [\"Level\", \"Channels\", \"BPP\", \"PSNR (dB)\", \"MSE\", \"MS-SSIM\", \"MS-SSIM (dB)\"]\n",
    "                writer.writerow(header)\n",
    "                for i in range(model.num_levels):\n",
    "                    writer.writerow([\n",
    "                        i, model.switch_list[i], bpp[i], psnr[i], mse[i]*255**2, msssim[i], msssim_db[i]\n",
    "                    ])\n",
    "            print(f\"\\n✅ Report saved to {report_file}\")\n",
    "\n",
    "        if args.report_path:\n",
    "            plt.style.use('seaborn-v0_8-whitegrid')\n",
    "            \n",
    "            print(\"Generating plots for metrics vs. model width...\")\n",
    "            channel_counts = sorted(model.switch_list)\n",
    "            original_indices = {ch: i for i, ch in enumerate(model.switch_list)}\n",
    "            sorted_indices = [original_indices[ch] for ch in channel_counts]\n",
    "            \n",
    "            plot_configs = [\n",
    "                ([psnr[i] for i in sorted_indices], \"Peak Signal-to-Noise Ratio (PSNR)\", \"PSNR (dB) (Higher is Better ↑)\", \"_psnr.png\"),\n",
    "                ([mse[i] * 255**2 for i in sorted_indices], \"Mean Squared Error (MSE)\", \"MSE (Lower is Better ↓)\", \"_mse.png\"),\n",
    "                ([bpp[i] for i in sorted_indices], \"Bits Per Pixel (bpp)\", \"bpp (Lower is Better ↓)\", \"_bpp.png\"),\n",
    "                ([msssim[i] for i in sorted_indices], \"Multi-Scale SSIM\", \"MS-SSIM (Higher is Better ↑)\", \"_msssim.png\"),\n",
    "                ([msssim_db[i] for i in sorted_indices], \"MS-SSIM (dB)\", \"MS-SSIM (dB) (Higher is Better ↑)\", \"_msssim_db.png\"),\n",
    "            ]\n",
    "            \n",
    "            for y_data, title, ylabel, suffix in plot_configs:\n",
    "                plt.figure(figsize=(10, 6))\n",
    "                plt.plot(channel_counts, y_data, 'o-')\n",
    "                plt.title(title, fontsize=16)\n",
    "                plt.xlabel(\"Model Width (# of Filters)\", fontsize=12)\n",
    "                plt.ylabel(ylabel, fontsize=12)\n",
    "                plt.xticks(channel_counts)\n",
    "                plt.savefig(args.report_path + suffix, dpi=300)\n",
    "                plt.close()\n",
    "\n",
    "            print(\"Generating Rate-Distortion curve plots...\")\n",
    "            plt.figure(figsize=(10, 7))\n",
    "            plt.plot(bpp, psnr, 'o--', color='#c44e52', label='SlimCAE')\n",
    "            for i, txt in enumerate(model.switch_list):\n",
    "                plt.text(bpp[i] * 1.02, psnr[i], f\"{txt} filters\", fontsize=12)\n",
    "            plt.title('Rate-Distortion Curve', fontsize=16)\n",
    "            plt.xlabel('Rate (Bits Per Pixel)', fontsize=12)\n",
    "            plt.ylabel('Quality (PSNR in dB)', fontsize=12)\n",
    "            plt.grid(True, which='both', linestyle='--')\n",
    "            plt.legend()\n",
    "            plt.savefig(args.report_path + \"_rd_psnr.png\", dpi=300)\n",
    "            plt.close()\n",
    "\n",
    "            plt.figure(figsize=(10, 7))\n",
    "            plt.plot(bpp, msssim_db, 'o--', color='#4c72b0', label='SlimCAE')\n",
    "            for i, txt in enumerate(model.switch_list):\n",
    "                plt.text(bpp[i] * 1.02, msssim_db[i], f\"{txt} filters\", fontsize=12)\n",
    "            plt.title('Rate-Distortion Curve', fontsize=16)\n",
    "            plt.xlabel('Rate (Bits Per Pixel)', fontsize=12)\n",
    "            plt.ylabel('Quality (MS-SSIM in dB)', fontsize=12)\n",
    "            plt.grid(True, which='both', linestyle='--')\n",
    "            plt.legend()\n",
    "            plt.savefig(args.report_path + \"_rd_msssim_db.png\", dpi=300)\n",
    "            plt.close()\n",
    "            \n",
    "            print(f\"✅ All plots saved to the directory of your report path.\")\n",
    "\n",
    "    elif num_models == 2:\n",
    "        print(\"\\n--- Running Two-Model Comparison ---\")\n",
    "        model_paths = args.checkpoint_paths\n",
    "        model_labels = [\"Before Fine-Tuning\", \"After Fine-Tuning\"]\n",
    "        results = {}\n",
    "\n",
    "        for i, path in enumerate(model_paths):\n",
    "            label = model_labels[i]\n",
    "            print(f\"\\n--- Evaluating Model: '{label}' ---\")\n",
    "            print(f\"Loading checkpoint from: {path}\")\n",
    "            \n",
    "            checkpoint = torch.load(path, map_location=device)\n",
    "            model.load_state_dict(checkpoint['model_state_dict'])\n",
    "            \n",
    "            bpp, psnr, mse, msssim, msssim_db = evaluate(model, test_loader, device)\n",
    "            results[label] = {\n",
    "                \"bpp\": bpp, \"psnr\": psnr, \"mse\": [m * 255**2 for m in mse],\n",
    "                \"msssim\": msssim, \"msssim_db\": msssim_db\n",
    "            }\n",
    "\n",
    "        if args.report_path:\n",
    "            report_dir = os.path.dirname(args.report_path)\n",
    "            if report_dir: os.makedirs(report_dir, exist_ok=True)\n",
    "            report_file = args.report_path + \".csv\"\n",
    "            with open(report_file, 'w', newline='') as f:\n",
    "                writer = csv.writer(f)\n",
    "                header = [\"Level\", \"Channels\", \n",
    "                          \"BPP_Before\", \"PSNR_Before\", \"MSE_Before\", \"MSSSIM_Before\", \"MSSSIM_DB_Before\",\n",
    "                          \"BPP_After\", \"PSNR_After\", \"MSE_After\", \"MSSSIM_After\", \"MSSSIM_DB_After\"]\n",
    "                writer.writerow(header)\n",
    "                for i in range(model.num_levels):\n",
    "                    row = [i, model.switch_list[i]]\n",
    "                    row.extend([results[model_labels[0]][k][i] for k in [\"bpp\", \"psnr\", \"mse\", \"msssim\", \"msssim_db\"]])\n",
    "                    row.extend([results[model_labels[1]][k][i] for k in [\"bpp\", \"psnr\", \"mse\", \"msssim\", \"msssim_db\"]])\n",
    "                    writer.writerow(row)\n",
    "            print(f\"\\n✅ Comparison report saved to {report_file}\")\n",
    "\n",
    "        if args.report_path:\n",
    "            plt.style.use('seaborn-v0_8-whitegrid')\n",
    "            \n",
    "            print(\"Generating comparison plots for metrics vs. model width...\")\n",
    "            channel_counts = sorted(model.switch_list)\n",
    "            plot_configs = [\n",
    "                (\"psnr\", \"Peak Signal-to-Noise Ratio (PSNR)\", \"PSNR (dB) (Higher is Better ↑)\"),\n",
    "                (\"mse\", \"Mean Squared Error (MSE)\", \"MSE (Lower is Better ↓)\"),\n",
    "                (\"bpp\", \"Bits Per Pixel (bpp)\", \"bpp (Lower is Better ↓)\"),\n",
    "                (\"msssim\", \"Multi-Scale SSIM\", \"MS-SSIM (Higher is Better ↑)\"),\n",
    "                (\"msssim_db\", \"MS-SSIM (dB)\", \"MS-SSIM (dB) (Higher is Better ↑)\"),\n",
    "            ]\n",
    "            \n",
    "            for metric, title, ylabel in plot_configs:\n",
    "                plt.figure(figsize=(10, 6))\n",
    "                original_indices = {ch: i for i, ch in enumerate(model.switch_list)}\n",
    "                sorted_indices = [original_indices[ch] for ch in channel_counts]\n",
    "                \n",
    "                before_data = [results[model_labels[0]][metric][i] for i in sorted_indices]\n",
    "                after_data = [results[model_labels[1]][metric][i] for i in sorted_indices]\n",
    "\n",
    "                plt.plot(channel_counts, before_data, 'o--', label=model_labels[0])\n",
    "                plt.plot(channel_counts, after_data, 's-', label=model_labels[1])\n",
    "                plt.title(title, fontsize=16)\n",
    "                plt.xlabel(\"Model Width (# of Filters)\", fontsize=12)\n",
    "                plt.ylabel(ylabel, fontsize=12)\n",
    "                plt.xticks(channel_counts)\n",
    "                plt.legend()\n",
    "                plt.savefig(f\"{args.report_path}_{metric}_vs_width.png\", dpi=300)\n",
    "                plt.close()\n",
    "\n",
    "            print(\"Generating comparison Rate-Distortion curve plots...\")\n",
    "            \n",
    "            plt.figure(figsize=(10, 7))\n",
    "            plt.plot(results[model_labels[0]]['bpp'], results[model_labels[0]]['psnr'], 'o--', label=model_labels[0])\n",
    "            plt.plot(results[model_labels[1]]['bpp'], results[model_labels[1]]['psnr'], 's-', label=model_labels[1])\n",
    "            for i, txt in enumerate(model.switch_list):\n",
    "                y_pos = max(results[model_labels[0]]['psnr'][i], results[model_labels[1]]['psnr'][i])\n",
    "                x_pos = results[model_labels[1]]['bpp'][i]\n",
    "                plt.text(x_pos, y_pos * 1.01, f\"{txt} filters\", fontsize=10, \n",
    "                         horizontalalignment='center', verticalalignment='bottom')\n",
    "            plt.title('Rate-Distortion Curve Comparison (PSNR)', fontsize=16)\n",
    "            plt.xlabel('Rate (Bits Per Pixel)', fontsize=12)\n",
    "            plt.ylabel('Quality (PSNR in dB)', fontsize=12)\n",
    "            plt.grid(True, which='both', linestyle='--')\n",
    "            plt.legend()\n",
    "            plt.savefig(f\"{args.report_path}_rd_psnr.png\", dpi=300)\n",
    "            plt.close()\n",
    "\n",
    "            plt.figure(figsize=(10, 7))\n",
    "            plt.plot(results[model_labels[0]]['bpp'], results[model_labels[0]]['msssim_db'], 'o--', label=model_labels[0])\n",
    "            plt.plot(results[model_labels[1]]['bpp'], results[model_labels[1]]['msssim_db'], 's-', label=model_labels[1])\n",
    "            for i, txt in enumerate(model.switch_list):\n",
    "                y_pos = max(results[model_labels[0]]['msssim_db'][i], results[model_labels[1]]['msssim_db'][i])\n",
    "                x_pos = results[model_labels[1]]['bpp'][i]\n",
    "                plt.text(x_pos, y_pos * 1.01, f\"{txt} filters\", fontsize=10, \n",
    "                         horizontalalignment='center', verticalalignment='bottom')\n",
    "            plt.title('Rate-Distortion Curve Comparison (MS-SSIM dB)', fontsize=16)\n",
    "            plt.xlabel('Rate (Bits Per Pixel)', fontsize=12)\n",
    "            plt.ylabel('Quality (MS-SSIM in dB)', fontsize=12)\n",
    "            plt.grid(True, which='both', linestyle='--')\n",
    "            plt.legend()\n",
    "            plt.savefig(f\"{args.report_path}_rd_msssim_db.png\", dpi=300)\n",
    "            plt.close()\n",
    "\n",
    "            print(f\"✅ All comparison plots saved to the directory of your report path.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Execution\n",
    "\n",
    "Choose one of the two options below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ▶️ Option 1: Run the Full Training Pipeline (From Scratch)\n",
    "\n",
    "Run the following cell to execute the complete training process: Stage 1 (initial training) followed by Stage 2 (lambda scheduling). This is for training a new model from the beginning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from types import SimpleNamespace\n",
    "\n",
    "# Define paths (already set up in Step 1)\n",
    "GDRIVE_BASE_PATH = \"/content/drive/MyDrive/SlimCAE\"\n",
    "LOCAL_DATA_PATH = \"/content/dataset\"\n",
    "CHECKPOINT_DIR = f'{GDRIVE_BASE_PATH}/checkpoints_torch/'\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "# --- 1. Stage 1 Training Configuration ---\n",
    "print(\"\\n--- CONFIGURING STAGE 1: TRAINING ---\")\n",
    "args_train = SimpleNamespace(\n",
    "    num_filters=192,\n",
    "    switch_list=[192, 144, 96, 72, 48],\n",
    "    lmbda=[2048, 1024, 512, 256, 128],\n",
    "    train_glob=f'{LOCAL_DATA_PATH}/train/train/', # Note the nested 'train' folder\n",
    "    checkpoint_dir=CHECKPOINT_DIR,\n",
    "    patchsize=128,\n",
    "    batchsize=8, # Default from your file\n",
    "    last_step=1000000,\n",
    "    resume=False # Set to True to resume from the latest checkpoint\n",
    ")\n",
    "train_model(args_train, DEVICE)\n",
    "\n",
    "# --- 2. Stage 2 Lambda Scheduling Configuration ---\n",
    "print(\"\\n--- CONFIGURING STAGE 2: LAMBDA SCHEDULING ---\")\n",
    "args_schedule = SimpleNamespace(\n",
    "    num_filters=192,\n",
    "    switch_list=[192, 144, 96, 72, 48],\n",
    "    lmbda=[2048, 1024, 512, 256, 128], # Initial lambdas\n",
    "    checkpoint_dir=CHECKPOINT_DIR,\n",
    "    train_glob=f'{LOCAL_DATA_PATH}/train/train/',\n",
    "    inputPath=f'{LOCAL_DATA_PATH}/test/test/', # Using test set for evaluation\n",
    "    patchsize=128,\n",
    "    batchsize=8\n",
    ")\n",
    "train_lambda_schedule(args_schedule, DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ▶️ Option 2: Evaluate a Pre-trained Final Model\n",
    "\n",
    "Run this cell if you have already trained a model and just want to evaluate `final_scheduled_model.pth` on the test dataset. This will print the final metrics and generate the performance plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from types import SimpleNamespace\n",
    "\n",
    "# Define paths (already set up in Step 1)\n",
    "GDRIVE_BASE_PATH = \"/content/drive/MyDrive/SlimCAE\"\n",
    "LOCAL_DATA_PATH = \"/content/dataset\"\n",
    "CHECKPOINT_DIR = f'{GDRIVE_BASE_PATH}/checkpoints_torch/'\n",
    "EVALUATION_DIR = f'{GDRIVE_BASE_PATH}/evaluation_torch/'\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "# --- Evaluation Configuration ---\n",
    "print(\"\\n--- CONFIGURING EVALUATION ---\")\n",
    "final_model_path = f'{CHECKPOINT_DIR}/final_scheduled_model.pth'\n",
    "\n",
    "args_eval = SimpleNamespace(\n",
    "    num_filters=192,\n",
    "    switch_list=[192, 144, 96, 72, 48],\n",
    "    inputPath=f'{LOCAL_DATA_PATH}/test/test/', # Note the nested 'test' folder\n",
    "    checkpoint_paths=[final_model_path], # Evaluate a single, final model\n",
    "    report_path=f'{EVALUATION_DIR}/final_report_single' # Base name for CSV and plots\n",
    ")\n",
    "\n",
    "if not os.path.exists(final_model_path):\n",
    "    print(f\"ERROR: Model not found at {final_model_path}\")\n",
    "    print(\"Please make sure the 'final_scheduled_model.pth' is in your Drive's checkpoint directory.\")\n",
    "else:\n",
    "    test_model(args_eval, DEVICE)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

